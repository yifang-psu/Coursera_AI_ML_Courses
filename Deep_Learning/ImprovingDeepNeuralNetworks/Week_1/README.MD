### Week 1 Learning Objectives 

* Give examples of how different types of initializations can lead to different results
* Examine the importance of initialization in complex neural networks
* Explain the difference between train/dev/test sets
* Diagnose the bias and variance issues in your model
* Assess the right time and place for using regularization methods such as dropout or L2 regularization
* Explain Vanishing and Exploding gradients and how to deal with them
* Use gradient checking to verify the accuracy of your backpropagation implementation
* Apply zeros initialization, random initialization, and He initialization
* Apply regularization to a deep learning model

### Three Assignements:
* Initialization:
  * Training your neural network requires specifying an initial value of the weights. A well-chosen initialization method helps the learning process. In this notebook assignment, try out a few different initializations and see how they lead to different results.
* Regularization:
  * In this assignment, practice to apply L2 regularization and dropout to a deep learning model that recommends positions to football players.
* Gradient Checking:
  * In this assignment, practice to implement gradient checking to check for errors in your implementation of a fraud detection model. 

### Week 3: Neural Networks Basics

* **What is this week's course about?**
  * Build a neural network with one hidden layer, using forward propagation and backpropagation.

* **Learning Objectives:**
  * Describe hidden units and hidden layers
  * Use units with a non-linear activation function, such as tanh
  * Implement forward and backward propagation
  * Apply random initialization to your neural network
  * Increase fluency in Deep Learning notations and Neural Network Representations
  * Implement a 2-class classification neural network with a single hidden layer
  * Compute the cross entropy loss

* **Programming Assignements**:
  * [Planar Data Classification with One Hidden Layer](https://github.com/yifang-psu/Coursera_AI_ML_Courses/blob/main/Deep_Learning/NeuralNetworks_and_DeepLearning/Week_2/Logistic_Regression_with_a_Neural_Network_mindset.ipynb): By the end of this assignment, you'll be able to:
    * Implement a 2-class classification neural network with a single hidden layer
    * Use units with a non-linear activation function, such as tanh
    * Compute the cross entropy loss
    * Implement forward and backward propagation
